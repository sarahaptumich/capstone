{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/sarahaptumich/capstone/blob/shaptonstall/Brace_angles.ipynb",
      "authorship_tag": "ABX9TyPF3lzsSoazJmaX8Goughx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahaptumich/capstone/blob/shaptonstall/Brace_Classifier_Hyperparameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BRACE Breakdancing\n",
        "We will use an annotated breakdancing dataset puclish in this GitHub: https://github.com/dmoltisanti/brace.git This repository contains the dataset published with the ECCV 2022 paper \"BRACE: The Breakdancing Competition Dataset for Dance Motion Synthesis\". We will attempt to train a model that will predict 3 distint breakdancing movements (toprock, powermove and footwork)"
      ],
      "metadata": {
        "id": "hCXy2NPmK1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-paramether Tunning."
      ],
      "metadata": {
        "id": "WycDaDi1hm2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o93rDh1-_3wg",
        "outputId": "a4ee86f0-cd62-48ca-8c61-7fc6919f695d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBBa-Hy4in7f",
        "outputId": "63e9d324-008d-4798-bb9f-40a778c68a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "import random as python_random\n",
        "import importlib.util\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "sqbdkLs62IUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(0,'./brace/utils/')\n",
        "# import keypoints_angles\n",
        "from keypoints_angles import  angles_distance_segments"
      ],
      "metadata": {
        "id": "0niPkFEV2RTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(0,'./brace/utils/clasification_models.py')\n",
        "import clasification_models"
      ],
      "metadata": {
        "id": "ZrfOrKkzl4Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_tuner import RandomSearch\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ],
      "metadata": {
        "id": "DKzAfAKpnAWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set random seed for reproductivity"
      ],
      "metadata": {
        "id": "3l9AV_5LMDyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_random_seeds():\n",
        "   np.random.seed(42)\n",
        "   python_random.seed(42)\n",
        "   tf.random.set_seed(42)\n",
        "   import os\n",
        "   os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "reset_random_seeds()\n",
        "\n",
        "# Disable all GPUs\n",
        "tf.config.set_visible_devices([], 'GPU')\n"
      ],
      "metadata": {
        "id": "q4KJYRQ9vgsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load processed dataClips, labels and names.\n",
        "See Brace_Dance_Classifier is you do not have the pre-processed dataclips"
      ],
      "metadata": {
        "id": "sxEmRDRrycJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load segment\n",
        "segments= pd.read_csv(Path('./brace/annotations/segments.csv'))\n",
        "# Load the TensorDataset\n",
        "with open('./brace/dataset/dataClips', 'rb') as f:\n",
        "    dataClips = pickle.load(f)\n",
        "\n",
        "# Load the training Subset\n",
        "with open('./brace/dataset/labels', 'rb') as f:\n",
        "    labels = pickle.load(f)\n",
        "\n",
        "# Load the testing Subset\n",
        "with open('./brace/dataset/names', 'rb') as f:\n",
        "    names = pickle.load(f)\n",
        "\n",
        "#encode labels from 0-2\n",
        "unique_categories = list(set(labels))\n",
        "category_to_int = {category: index for index, category in enumerate(unique_categories)}\n",
        "encoded_categories = [category_to_int[category] for category in labels]\n",
        "#get flatted clips\n",
        "flattened_clips = [clip.reshape(clip.shape[0], -1) for clip in dataClips]"
      ],
      "metadata": {
        "id": "sIoe7sJLKawx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features= segments.copy()\n",
        "features['uid']= pd.Categorical(features['uid'], categories=names, ordered=True)\n",
        "features= features.sort_values(by='uid')\n",
        "features['frames']= features['end_frame']- features['start_frame']"
      ],
      "metadata": {
        "id": "TJyQgV7Qh5be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_lengths = [len(seq) for seq in flattened_clips]\n",
        "maxlen = np.percentile(sequence_lengths, 90)\n",
        "print(\"Max Lenght 90th percentile:\",maxlen)"
      ],
      "metadata": {
        "id": "z8AhMo7rdxwi",
        "outputId": "12b8a490-3472-409b-9bc1-c0858b8ace60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Lenght 90th percentile: 471.9000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper parameter tuning baseline model\n",
        "Additional information on parameter tunning with Keras can be found her: https://keras.io/guides/keras_tuner/getting_started/\n",
        "\n",
        "Tensor Board:\n",
        "* https://www.tensorflow.org/tensorboard/get_started\n",
        "* https://www.youtube.com/watch?v=PG4XGqUeYnM"
      ],
      "metadata": {
        "id": "ygaM7-oXe_WV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We will perform hyperparameter tuning on our model with DataClips only"
      ],
      "metadata": {
        "id": "O2PKyowzoFiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare data by adding padding and onehot code the categories.\n",
        "padded_clips = pad_sequences(flattened_clips, padding='pre', truncating='pre', maxlen=int(maxlen), dtype='float32')\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_clips, encoded_categories, test_size=0.20, random_state=42)\n",
        "\n",
        "y_train_onehot = to_categorical(y_train, num_classes=3)\n",
        "y_test_onehot = to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "-roIcMJjoXed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "num_classes = 3"
      ],
      "metadata": {
        "id": "oFkIYGv2pFtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelDataClips=clasification_models.MdataClips(input_shape=input_shape, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "UxmPJbVBpxAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_name= 'modelDataClips_tuning'\n",
        "tuner = RandomSearch(\n",
        "    modelDataClips,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuner_results',\n",
        "    project_name=project_name\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "        TensorBoard(log_dir=os.path.join('logs', project_name)),\n",
        "        ModelCheckpoint(f'best_model_{project_name}.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "\n",
        "tuner.search(X_train, y_train_onehot, epochs=10, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.save(f'best_model_{project_name}.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fr2zpFVp-27",
        "outputId": "52dff3b7-dde1-4439-81d0-0612ee2231eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 12m 25s]\n",
            "val_accuracy: 0.6866359710693359\n",
            "\n",
            "Best val_accuracy So Far: 0.8894008994102478\n",
            "Total elapsed time: 01h 33m 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(\"./best_model_modelDataClips_tuning.h5\")\n",
        "test_loss, test_accuracy = loaded_model.evaluate(X_test, y_test_onehot)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgnBQ-JtCwps",
        "outputId": "019b1dfd-1ca8-427d-8887-354ed71a0b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 6s 618ms/step - loss: 0.3594 - accuracy: 0.8598\n",
            "Test Loss: 0.35940009355545044, Test Accuracy: 0.8597785830497742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "NWKZjqr8oPlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparamether tuning on the feature and DataClips model"
      ],
      "metadata": {
        "id": "f7LcZKrjNNWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the logs from previous\n",
        "\n",
        "!rm -rf /logs/"
      ],
      "metadata": {
        "id": "gNHeWdtudXZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Prepocess additional features to augment our model\n",
        "reset_random_seeds()\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('seq', OneHotEncoder(), ['seq_idx']),\n",
        "        ('frames', OneHotEncoder(), ['frames'])\n",
        "    ]\n",
        ")\n",
        "\n",
        "features_preprocessed = preprocessor.fit_transform(features[['seq_idx', 'frames']])\n",
        "features_preprocessed = features_preprocessed.toarray()"
      ],
      "metadata": {
        "id": "lQsKh_BaNlab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_clips = pad_sequences(flattened_clips, padding='pre', truncating='pre', maxlen=int(maxlen), dtype='float32')\n",
        "\n",
        "X_train_clips, X_test_clips, X_train_features, X_test_features, y_train, y_test = train_test_split(\n",
        "    padded_clips, features_preprocessed, encoded_categories, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "y_train_onehot = to_categorical(y_train, num_classes=3)\n",
        "y_test_onehot = to_categorical(y_test, num_classes=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "ejmyllmUNZiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_random_seeds()\n",
        "input_shape_clips = (X_train_clips.shape[1], X_train_clips.shape[2])\n",
        "input_shape_features = (X_train_features.shape[1],)\n",
        "\n",
        "\n",
        "featureDataClips=clasification_models.FeatureModel(input_shape_clips, input_shape_features, num_classes=3)\n",
        "\n",
        "project_name= 'features_tuning'\n",
        "tuner = RandomSearch(\n",
        "    featureDataClips,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    directory='tuner_results',\n",
        "    project_name= project_name\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "        TensorBoard(log_dir=os.path.join('logs', project_name)),\n",
        "        ModelCheckpoint(f'best_model_{project_name}.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "tuner.search([X_train_clips, X_train_features], y_train_onehot, epochs=10, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.save(f'best_model_{project_name}.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1iNRF_QN_uF",
        "outputId": "4608ea5e-67f4-435c-9a3d-94bd03a1b17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 27s]\n",
            "val_accuracy: 0.8064516186714172\n",
            "\n",
            "Best val_accuracy So Far: 0.8341013789176941\n",
            "Total elapsed time: 00h 15m 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(\"./best_model_features_tuning.h5\")\n",
        "test_loss, test_accuracy = loaded_model.evaluate([X_test_clips, X_test_features], y_test_onehot)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO-TysfGdgW5",
        "outputId": "ff9d3f2b-8a18-4551-dcd6-31fb1fafc957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 60ms/step - loss: 0.4346 - accuracy: 0.8266\n",
            "Test Loss: 0.4345933496952057, Test Accuracy: 0.8265682458877563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tune a model that uset DataClip, features and distance and angles"
      ],
      "metadata": {
        "id": "cqCCW0Sidk-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the logs from previous\n",
        "!rm -rf /logs/"
      ],
      "metadata": {
        "id": "yKcQpAnJdwWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hip_knee_ankle_angles= angles_distance_segments(flattened_clips)\n",
        "# Padding sequences\n",
        "padded_clips = pad_sequences(flattened_clips, padding='pre', truncating='pre', maxlen=int(maxlen), dtype='float32')\n",
        "padded_angles = pad_sequences(hip_knee_ankle_angles, padding='pre', truncating='pre', maxlen=int(maxlen), dtype='float32')\n",
        "\n",
        "#Scaler\n",
        "n_samples = padded_angles.shape[0]\n",
        "n_features = padded_angles.shape[1] * padded_angles.shape[2]\n",
        "flattened_angles = padded_angles.reshape(n_samples, n_features)\n",
        "scaler = StandardScaler()\n",
        "X_temp_angles, X_test_angles, _, _ = train_test_split(flattened_angles, encoded_categories, test_size=0.2, random_state=42)\n",
        "scaler.fit(X_temp_angles)\n",
        "X_train_angles_norm = scaler.transform(X_temp_angles)\n",
        "X_test_angles_norm = scaler.transform(X_test_angles)\n",
        "X_train_angles = X_train_angles_norm.reshape(-1, padded_angles.shape[1], padded_angles.shape[2])\n",
        "X_test_angles = X_test_angles_norm.reshape(-1, padded_angles.shape[1], padded_angles.shape[2])\n",
        "\n",
        "encoded_categories_array = np.array(encoded_categories)\n",
        "labels_onehot = to_categorical(encoded_categories_array, num_classes=3)\n",
        "\n",
        "X_train_clips, X_test_clips, X_train_features, X_test_features, y_train_onehot, y_test_onehot = train_test_split(\n",
        "    padded_clips, features_preprocessed, labels_onehot, test_size=0.2, random_state=42, stratify=encoded_categories)"
      ],
      "metadata": {
        "id": "yv3QyS4qd9zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_random_seeds()\n",
        "\n",
        "CombinedDataClips=clasification_models.CombinedModel(\n",
        "    input_shape_clips=X_train_clips.shape[1:],\n",
        "    input_shape_angles=X_train_angles.shape[1:],\n",
        "    input_shape_features=X_train_features.shape[1:],\n",
        "    num_classes=3\n",
        ")\n",
        "project_name= 'combined_tuning'\n",
        "tuner = RandomSearch(\n",
        "    CombinedDataClips,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    directory='tuner_results',\n",
        "    project_name= project_name\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "        TensorBoard(log_dir=os.path.join('logs', project_name)),\n",
        "        ModelCheckpoint(f'best_model_{project_name}.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "tuner.search([X_train_clips, X_train_angles, X_train_features], y_train_onehot, epochs=7, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.save(f'best_model_{project_name}.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bxPMtdqeIsS",
        "outputId": "84696a8c-531b-4eba-9906-22f2c6fdce3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 02m 28s]\n",
            "val_accuracy: 0.7327188849449158\n",
            "\n",
            "Best val_accuracy So Far: 0.764976978302002\n",
            "Total elapsed time: 00h 21m 20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model(\"./best_model_combined_tuning.h5\")\n",
        "test_loss, test_accuracy = loaded_model.evaluate([X_test_clips, X_test_angles, X_test_features], y_test_onehot)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUQsChBLfClK",
        "outputId": "43b1dcb1-485a-4adb-d3c4-0e35fb05e91a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 4s 268ms/step - loss: 0.5741 - accuracy: 0.7454\n",
            "Test Loss: 0.5740699172019958, Test Accuracy: 0.7453874349594116\n"
          ]
        }
      ]
    }
  ]
}