{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxNrUwFG/WK/qupjIrgRdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahaptumich/capstone/blob/shaptonstall/brace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q_c2JZ5xGiW",
        "outputId": "7f8437dd-2c61-422a-ab1f-5ad00f920262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Github/capstone/brace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjUD3TpP3nCf",
        "outputId": "f33345b3-65b6-4836-dc63-690b8a43e22c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/capstone/brace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZktF17T3pIo",
        "outputId": "667658c3-95a3-46e8-dcc1-397adeb1f06a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/     brace_train.pkl     \u001b[01;34mfigures\u001b[0m/         README.md           \u001b[01;34mutils\u001b[0m/\n",
            "bracedataset.py  brace_train.pth     lstm_model2.pth  tensor_dataset.pkl  videos_info.csv\n",
            "brace_test.pkl   \u001b[01;34mdataset\u001b[0m/            lstm_model.pth   test_subset.pkl\n",
            "brace_test.pth   dataset_pytorch.py  \u001b[01;34m__pycache__\u001b[0m/     train_subset.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "qsLkZ6u4TAyK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Github/capstone/brace')"
      ],
      "metadata": {
        "id": "SgLOxprD3ypr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import bracedataset\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import TensorDataset\n",
        "from tqdm import tqdm\n",
        "from pathlib import PosixPath\n",
        "import pickle\n",
        "import re\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import json\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "-1pDE0Lr33BQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain BRACE dataset clips and labels, only need to to this once, they are saved for future reference\n"
      ],
      "metadata": {
        "id": "tYYGYVWMngFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #load paths\n",
        "# sequences_path = Path('/content/drive/MyDrive/Github/capstone/brace/dataset')\n",
        "# pose_jsons = list(Path(sequences_path).rglob('**/*.json'))\n",
        "# segments= pd.read_csv(Path('/content/drive/MyDrive/Github/capstone/brace/annotations/segments.csv'))\n",
        "# #get clips\n",
        "# dataClips, labels=bracedataset.BraceDataset(segments, pose_jsons)\n",
        "# #encode labels from 0-2\n",
        "# unique_categories = list(set(labels))\n",
        "# category_to_int = {category: index for index, category in enumerate(unique_categories)}\n",
        "# encoded_categories = [category_to_int[category] for category in labels]\n",
        "\n",
        "# #get max length of the keypoints\n",
        "# max_length = max(seq.shape[0] for seq in dataClips)\n",
        "\n",
        "# #pad tensor so they are of the same lenght\n",
        "# dataClips_tensors=[np.pad(array.astype(np.float32), ((0, max_length - array.shape[0]), (0, 0), (0, 0)), 'constant', constant_values=0) for array in dataClips]\n",
        "# dataClips_tensors=torch.tensor(dataClips_tensors)\n",
        "# #convert labels to tensors\n",
        "# label_tensors = np.array(encoded_categories)\n",
        "# label_tensors=torch.tensor(label_tensors)\n",
        "# ##SPLIT SET FOR REPRODUCTIVITY\n",
        "# dataset = TensorDataset(dataClips_tensors, label_tensors)\n",
        "# # Set seed for reproducibility\n",
        "# torch.manual_seed(42)\n",
        "\n",
        "# # Determine split sizes\n",
        "# train_size = int(0.8 * len(dataset))\n",
        "# test_size = len(dataset) - train_size\n",
        "\n",
        "# # Split dataset\n",
        "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# print(f\"Training set size: {len(train_dataset)}\")\n",
        "# print(f\"Testing set size: {len(test_dataset)}\")\n",
        "# # Save the TensorDataset\n",
        "# with open('tensor_dataset.pkl', 'wb') as f:\n",
        "#     pickle.dump(dataset, f)\n",
        "\n",
        "# # Save the Subset\n",
        "# with open('train_subset.pkl', 'wb') as f:\n",
        "#     pickle.dump(train_dataset, f)\n",
        "# with open('test_subset.pkl', 'wb') as f:\n",
        "#     pickle.dump(test_dataset, f)"
      ],
      "metadata": {
        "id": "bdAacfsqjl1k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load previously saved dataset"
      ],
      "metadata": {
        "id": "mw0S9lN1okOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorDataset\n",
        "with open('tensor_dataset.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "# Load the training Subset\n",
        "with open('train_subset.pkl', 'rb') as f:\n",
        "    train_dataset = pickle.load(f)\n",
        "\n",
        "# Load the testing Subset\n",
        "with open('test_subset.pkl', 'rb') as f:\n",
        "    test_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "tDJX7sw_orzu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16  # Adjust based on your system's capability and the model's requirements\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "oV0A7N1TL14h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this to load the dataset"
      ],
      "metadata": {
        "id": "rt-EqlkRYyQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes=3):  # Default set to 3\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "k329g0DixKLI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JwbV2Rbv1Iqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "PWJJxnJkqmgC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "input_size = 17 * 2  # Assuming you flatten the last two dimensions\n",
        "hidden_size = 128  # Example value\n",
        "num_layers = 2  # Example value\n",
        "num_classes = 3  # Adjust based on your task\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Training step\n",
        "    for sequences, labels in train_loader:\n",
        "        sequences = sequences.to(device).view(-1, 1280, 34)  # Adjust shape for LSTM\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(sequences)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "E02KGiJWD_nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # After training loop\n",
        "# model_path = \"lstm_model2.pth\"\n",
        "# torch.save(model.state_dict(), model_path)\n",
        "# print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "id": "ac2T2fEQZLaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "# model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\n",
        "# print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28hYuWU8pgy4",
        "outputId": "fcaf8c66-19f4-4551-b043-8bd912f2b3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()  # Ensure model is in evaluation mode\n",
        "with torch.no_grad():\n",
        "    for sequences, labels in test_loader:\n",
        "        sequences = sequences.to(device).view(-1, 1280, 34)  # Adjust shape for LSTM\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(sequences)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the test dataset: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "s64_9n-RpocJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}