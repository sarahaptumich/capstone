{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOZBoB1m/i1xLjGZ5mLRJ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahaptumich/capstone/blob/shaptonstall/brace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q_c2JZ5xGiW",
        "outputId": "2480d7c2-0aac-476e-89a0-513363d38a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Github/capstone/brace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjUD3TpP3nCf",
        "outputId": "11079661-ec56-4bdd-c722-730314ea4e6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/capstone/brace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZktF17T3pIo",
        "outputId": "47ee1bdf-65d1-4c68-ebc6-dd4e1e05530b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/     brace_test.pth   \u001b[01;34mdataset\u001b[0m/            lstm_model.pth  \u001b[01;34mutils\u001b[0m/\n",
            "bracedataset.py  brace_train.pkl  dataset_pytorch.py  \u001b[01;34m__pycache__\u001b[0m/    videos_info.csv\n",
            "brace_test.pkl   brace_train.pth  \u001b[01;34mfigures\u001b[0m/            README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "qsLkZ6u4TAyK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Github/capstone/brace')"
      ],
      "metadata": {
        "id": "SgLOxprD3ypr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import bracedataset\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import TensorDataset\n",
        "from tqdm import tqdm\n",
        "from pathlib import PosixPath\n",
        "import pickle\n",
        "import re\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import json\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "-1pDE0Lr33BQ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_path = Path('/content/drive/MyDrive/Github/capstone/brace/dataset')\n",
        "pose_jsons = list(Path(sequences_path).rglob('**/*.json'))\n",
        "segments= pd.read_csv(Path('/content/drive/MyDrive/Github/capstone/brace/annotations/segments.csv'))"
      ],
      "metadata": {
        "id": "bdAacfsqjl1k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataClips, labels=bracedataset.BraceDataset(segments, pose_jsons)"
      ],
      "metadata": {
        "id": "iC1fCke5wBjB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_categories = list(set(labels))\n",
        "category_to_int = {category: index for index, category in enumerate(unique_categories)}\n",
        "encoded_categories = [category_to_int[category] for category in labels]\n"
      ],
      "metadata": {
        "id": "J2Uay3I71UGG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataClips), type(labels)"
      ],
      "metadata": {
        "id": "3guXdLHexZcs",
        "outputId": "7d511325-3de0-485f-a016-45b13477873d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1352, list)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(seq.shape[0] for seq in dataClips)\n"
      ],
      "metadata": {
        "id": "3Z9je_yq4yy2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataClips_tensors=[np.pad(array.astype(np.float32), ((0, max_length - array.shape[0]), (0, 0), (0, 0)), 'constant', constant_values=0) for array in dataClips]\n",
        "dataClips_tensors=torch.tensor(dataClips_tensors)"
      ],
      "metadata": {
        "id": "IivY4t4E6NYZ",
        "outputId": "7bd7ee22-3d78-4f88-d1b3-fd839365f774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-742728265591>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  dataClips_tensors=torch.tensor(dataClips_tensors)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_tensors = np.array(encoded_categories)\n",
        "label_tensors=torch.tensor(label_tensors)"
      ],
      "metadata": {
        "id": "7VdNuvP22iNa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_tensors.shape, dataClips_tensors.shape"
      ],
      "metadata": {
        "id": "NgJtQZ4u3RhJ",
        "outputId": "9f0bd115-554b-4c93-d3ee-fe4f65fbffe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1352]), torch.Size([1352, 1280, 17, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(dataClips_tensors, label_tensors)\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Determine split sizes\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Split dataset\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Testing set size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "JHtJbY8dCfDh",
        "outputId": "9eff2378-e160-4723-a25e-6368c7597465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1081\n",
            "Testing set size: 271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the TensorDataset\n",
        "# with open('tensor_dataset.pkl', 'wb') as f:\n",
        "#     pickle.dump(dataset, f)\n",
        "\n",
        "# # Save the Subset\n",
        "# with open('train_subset.pkl', 'wb') as f:\n",
        "#     pickle.dump(train_dataset, f)\n",
        "# with open('test_subset.pkl', 'wb') as f:\n",
        "#     pickle.dump(test_dataset, f)"
      ],
      "metadata": {
        "id": "aggmXfATCvA1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16  # Adjust based on your system's capability and the model's requirements\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "oV0A7N1TL14h"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this to load the dataset"
      ],
      "metadata": {
        "id": "rt-EqlkRYyQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes=3):  # Default set to 3\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "k329g0DixKLI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JwbV2Rbv1Iqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.9)  # Applies an exponential decay to the learning rate\n"
      ],
      "metadata": {
        "id": "VnH_xQTSb85B"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "input_size = 17 * 2  # Assuming you flatten the last two dimensions\n",
        "hidden_size = 128  # Example value\n",
        "num_layers = 2  # Example value\n",
        "num_classes = 3  # Adjust based on your task\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Training step\n",
        "    for sequences, labels in train_loader:\n",
        "        sequences = sequences.to(device).view(-1, 1280, 34)  # Adjust shape for LSTM\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sequences)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    scheduler.step()  # Update the learning rate after each epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, LR: {scheduler.get_last_lr()[0]}')"
      ],
      "metadata": {
        "id": "E02KGiJWD_nh",
        "outputId": "3fa365da-06f7-46d2-f099-4ebf95458140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.0934, LR: 0.0009000000000000001\n",
            "Epoch [2/10], Loss: 1.0889, LR: 0.0008100000000000001\n",
            "Epoch [3/10], Loss: 1.1044, LR: 0.000729\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-29464fab9f30>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training loop\n",
        "model_path = \"lstm_model2.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "id": "ac2T2fEQZLaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "# model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\n",
        "# print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28hYuWU8pgy4",
        "outputId": "fcaf8c66-19f4-4551-b043-8bd912f2b3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()  # Ensure model is in evaluation mode\n",
        "with torch.no_grad():\n",
        "    for sequences, labels in test_loader:\n",
        "        sequences = sequences.to(device).view(-1, 1280, 34)  # Adjust shape for LSTM\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(sequences)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the test dataset: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "s64_9n-RpocJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}