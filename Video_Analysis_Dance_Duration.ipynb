{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahaptumich/capstone/blob/main/Video_Analysis_Dance_Duration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video Analysis\n",
        "This code is adapted from a project developd by analytics vidhya\n",
        "https://www.analyticsvidhya.com/blog/2018/09/deep-learning-video-classification-python/\n",
        "\n",
        "This code uses, dowload the videos and place them in the video folder\n",
        "The link is for the test bboy. (https://drive.google.com/file/d/1ygw6m_VFF3V86tremTi8B3ADSTaQZKZX/view?usp=sharing)\n",
        "The link is for the train bboy. (https://drive.google.com/file/d/1TfvGfqw9rEmIFa2JAcHVmKAwO-7GU0s3/view?usp=sharing)"
      ],
      "metadata": {
        "id": "3aXCJJCzL3f2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pz0lTnh3WUV",
        "outputId": "0225bb50-88df-49b2-8b9e-7cdf8020498b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmIQG_8J3XYf",
        "outputId": "dfaf9040-d0b9-49a5-d004-914202028da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHC0DWK13Xs-",
        "outputId": "0164e543-196a-4eca-f90f-b2e5e9fff5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bboy_frames  train_bboy_frames   train_labels.csv\t\t    videos\n",
            "test_labels.csv   train_bboy_frames2  train_labels_-mT5x-j_TpI.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OZvU_wex41i"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.transform import resize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aplPWJ0HIUv9",
        "outputId": "d76a29b2-778b-4dda-d124-981df464a7df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos/videos\n",
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos/train_bboy_frames\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Making frames from a video\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Save train frames into test_bboy_frames\n",
        "%cd videos\n",
        "\n",
        "# Call train set\n",
        "count = 0\n",
        "videoFile = \"train_bboy.MOV\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "\n",
        "# Save train frames into test_bboy_frames\n",
        "%cd ../train_bboy_frames\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# back to the directory\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R2xyLVb4IhB",
        "outputId": "9f5de9ce-8613-4fdf-a889-69061333ff6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTCKvWlw4iam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd55697-1081-4f2a-a296-a4cc8b9b66d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bboy_frames  train_bboy_frames   train_labels.csv\t\t    videos\n",
            "test_labels.csv   train_bboy_frames2  train_labels_-mT5x-j_TpI.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2oaDUvRI_eG",
        "outputId": "b56d6f61-db39-44d8-874a-4d523481dd88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos/videos\n",
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos/test_bboy_frames\n",
            "Done!\n",
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos\n"
          ]
        }
      ],
      "source": [
        "# change to the videos\n",
        "%cd videos\n",
        "\n",
        "# Test\n",
        "count = 0\n",
        "videoFile = \"test_bboy.mov\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "\n",
        "# Save test frames into test_bboy_frames\n",
        "%cd ../test_bboy_frames\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")\n",
        "\n",
        "# Back to the directory\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A191TEJrwys",
        "outputId": "60267470-3fe6-48b3-a851-b79cfb38e4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bboy_frames  train_bboy_frames   train_labels.csv\t\t    videos\n",
            "test_labels.csv   train_bboy_frames2  train_labels_-mT5x-j_TpI.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfgKyYGt6_PC"
      },
      "outputs": [],
      "source": [
        "# Labeling manually\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Function to display a frame and collect manual annotation\n",
        "def annotate_frame(frame_path, breaker1_id, breaker2_id):\n",
        "    # Load the frame\n",
        "    frame = cv2.imread(frame_path)\n",
        "\n",
        "    # Display the frame\n",
        "    display(Image(data=cv2.imencode('.png', frame)[1].tobytes()))\n",
        "\n",
        "    # Create a dropdown widget for manual annotation\n",
        "    label_dropdown = widgets.Dropdown(\n",
        "        options=[0, breaker1_id, breaker2_id], # breaker2_id : 'breaker2', breaker1_id : 'breaker1', 0 : 'not dancing'\n",
        "        description='Label:',\n",
        "        layout={'width': 'max-content'}\n",
        "    )\n",
        "\n",
        "    # Display the dropdown widget\n",
        "    display(label_dropdown)\n",
        "\n",
        "    return label_dropdown\n",
        "\n",
        "# Function to annotate all frames in a directory\n",
        "def annotate_frames(frames_dir, labels_output_file, breaker1_id, breaker2_id):\n",
        "    labels = []\n",
        "\n",
        "    for filename in sorted(os.listdir(frames_dir)):\n",
        "        if filename.endswith('.png'):\n",
        "            frame_path = os.path.join(frames_dir, filename)\n",
        "\n",
        "            # Display the frame and collect manual annotation\n",
        "            label_dropdown = annotate_frame(frame_path, breaker1_id, breaker2_id)\n",
        "\n",
        "            # Wait for user input and retrieve the selected label\n",
        "            user_input = widgets.VBox(children=[label_dropdown])\n",
        "            display(user_input)\n",
        "\n",
        "            label = label_dropdown.value\n",
        "            labels.append((filename, label))\n",
        "\n",
        "    # Save the labels to a file\n",
        "    with open(labels_output_file, 'w') as f:\n",
        "        for filename, label in labels:\n",
        "            f.write(f\"{filename},{label}\\n\")\n",
        "\n",
        "# Example usage\n",
        "# You can use this code to label frames manually\n",
        "# 'write_csv.ipynb' can be used to create a csv file.\n",
        "\n",
        "# Load all sheets into a dictionary of DataFrames, this csv file is for the future video analysis\n",
        "# sequence_df = pd.read_csv('sequences.csv')\n",
        "# sequence_df has records what frames started dancing and stop dancing. So, we can apply them\n",
        "# into labeling them in train sets and test sets.\n",
        "\n",
        "# In the directory 'videos', many dancing videos with how to label them in own frames.\n",
        "\n",
        "# The below are how to label in every dancing video.\n",
        "\n",
        "# frames_dir = \"videos/brace_frames/-mT5x-j_TpI\"  # Directory containing preprocessed frames\n",
        "# labels_output_file = \"train_labels_-mT5x-j_TpI.csv\"  # File to save the frame labels\n",
        "\n",
        "# breaker1_id = sequence_df[sequence_df['dancer']=='wing']['dancer_id'].iloc[0]\n",
        "# breaker2_id = sequence_df[sequence_df['dancer']=='robin']['dancer_id'].iloc[0]\n",
        "# annotate_frames(frames_dir, labels_output_file, breaker1_id, breaker2_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9eP_LqOAhy1",
        "outputId": "60167757-e220-41b9-87bd-229f18b802d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: keras.utils in /usr/local/lib/python3.10/dist-packages (1.0.13)',\n",
              " 'Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from keras.utils) (2.15.0)']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "!!pip install keras.utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPUmBND5sSNR",
        "outputId": "c10b1bd7-3752-417d-a763-99e9e1d2538d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bboy_frames  train_bboy_frames   train_labels.csv\t\t    videos\n",
            "test_labels.csv   train_bboy_frames2  train_labels_-mT5x-j_TpI.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7QkRl09YrxY",
        "outputId": "502e8832-2c1f-41bb-ecfe-b62605e5fa2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos/train_bboy_frames\n",
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import callbacks\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# we have train & test labels in advance for testing the model.\n",
        "data = pd.read_csv('train_labels.csv')\n",
        "\n",
        "\n",
        "#  into test_bboy_frames\n",
        "%cd train_bboy_frames\n",
        "\n",
        "X = []\n",
        "for img_name in data.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)\n",
        "X = np.array(X)\n",
        "\n",
        "y = data.Class\n",
        "dummy_y = tensorflow.keras.utils.to_categorical(y)    # one hot encoding Classes\n",
        "\n",
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
        "    image.append(a)\n",
        "X = np.array(image)\n",
        "\n",
        "# Back to the directory\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUCgEF9sZzMJ"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "X = preprocess_input(X)      # preprocessing the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7wfonwjYr4k"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGjAQEcNaRh4"
      },
      "outputs": [],
      "source": [
        "# Load the libraries\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Load the VGG16 pretrained model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "e1lAv4Grwynh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions using this model for X_train and X_valid, get the features,\n",
        "# and then use those features to retrain the model.\n",
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "X_train.shape, X_valid.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se5kSTafxN1G",
        "outputId": "806b4e5e-a42a-445b-f4be-66b5beb74304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 121s 21s/step\n",
            "3/3 [==============================] - 51s 12s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((157, 7, 7, 512), (68, 7, 7, 512))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTOepeQpy7QS",
        "outputId": "13bada6c-319d-4a1e-9d0b-f93441a42b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to pass it to our neural network, we have to reshape it to 1-D\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])      # converting to 1-D\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1]*X_valid.shape[2]*X_valid.shape[3])\n"
      ],
      "metadata": {
        "id": "8k78IGRqxM8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the images and make them zero-centered which helps the model to converge faster.\n",
        "train = X_train/X_train.max()      # centering the data\n",
        "X_valid = X_valid/X_train.max()\n"
      ],
      "metadata": {
        "id": "s6KFCMGJxksS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i. Building the model\n",
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
        "model.add(Dense(3, activation='softmax'))    # output layer\n"
      ],
      "metadata": {
        "id": "jUMcKWkPxu9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s check the summary of the model using the summary() function:\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dKlttlPx8KD",
        "outputId": "3f2cc733-92de-4698-a3ac-a0acd0a7006b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              25691136  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25694211 (98.02 MB)\n",
            "Trainable params: 25694211 (98.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a hidden layer with 1,024 neurons and an output layer with 3 neurons (since we have 3 classes to predict)."
      ],
      "metadata": {
        "id": "u1rmIUg30U07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-k08azMhTmm"
      },
      "outputs": [],
      "source": [
        "# ii. Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oay0Rs0nhTzY",
        "outputId": "9d9721b6-fc78-4edd-8c81-8580128469a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 5s 855ms/step - loss: 0.7614 - accuracy: 0.7452 - val_loss: 0.3882 - val_accuracy: 0.9265\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 0.2357 - accuracy: 0.9363 - val_loss: 0.3363 - val_accuracy: 0.9118\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 3s 508ms/step - loss: 0.1163 - accuracy: 0.9873 - val_loss: 0.2483 - val_accuracy: 0.9412\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 3s 522ms/step - loss: 0.0496 - accuracy: 0.9873 - val_loss: 0.2399 - val_accuracy: 0.9559\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 3s 594ms/step - loss: 0.0295 - accuracy: 0.9936 - val_loss: 0.2325 - val_accuracy: 0.9559\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 4s 786ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9559\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 3s 515ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9559\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9559\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 3s 506ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9559\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 3s 549ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9559\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 4s 825ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9559\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 3s 521ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9559\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9559\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9559\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 3s 527ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9559\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 4s 824ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9559\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 3s 528ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9559\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9559\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 3s 526ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9559\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9559\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 4s 818ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9559\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 3s 548ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9559\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 4s 820ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9559\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9559\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 3s 709ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9559\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 4s 696ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9559\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 3s 549ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9559\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9559\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 3s 513ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9559\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 3s 732ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9559\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 4s 695ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9559\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9559\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 3s 536ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9559\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 3s 534ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9559\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 3s 718ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9559\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 4s 684ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9559\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 3s 527ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9559\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 3s 528ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9559\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9559\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 3s 695ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9559\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 4s 701ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9559\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 3s 523ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9559\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 3s 515ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9559\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9559\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 3s 642ms/step - loss: 9.8124e-04 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9559\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 4s 756ms/step - loss: 9.5422e-04 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9559\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 9.2452e-04 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9559\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 3s 514ms/step - loss: 9.0008e-04 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9559\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 3s 526ms/step - loss: 8.7382e-04 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9559\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 3s 644ms/step - loss: 8.4939e-04 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9559\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 4s 781ms/step - loss: 8.2580e-04 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9559\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 3s 519ms/step - loss: 8.0350e-04 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9559\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 7.8449e-04 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9559\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 7.6187e-04 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9559\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 3s 588ms/step - loss: 7.4225e-04 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9559\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 4s 820ms/step - loss: 7.2368e-04 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9559\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 3s 511ms/step - loss: 7.0508e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9559\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 6.9032e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9559\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 3s 513ms/step - loss: 6.7191e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9559\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 6.5589e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9559\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 4s 796ms/step - loss: 6.4063e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9559\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 6.2594e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9559\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 3s 509ms/step - loss: 6.1118e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9559\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 3s 519ms/step - loss: 5.9681e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9559\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 3s 536ms/step - loss: 5.8356e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9559\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 4s 839ms/step - loss: 5.7074e-04 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9559\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 5.5851e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9559\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 3s 515ms/step - loss: 5.4572e-04 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9559\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 3s 534ms/step - loss: 5.3434e-04 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9559\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 3s 514ms/step - loss: 5.2271e-04 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9559\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 4s 875ms/step - loss: 5.1249e-04 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9559\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 5.0152e-04 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9559\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 4.9094e-04 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9559\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 3s 509ms/step - loss: 4.8112e-04 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9559\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 3s 539ms/step - loss: 4.7159e-04 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9559\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 4s 819ms/step - loss: 4.6247e-04 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9559\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 3s 540ms/step - loss: 4.5363e-04 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9559\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 4.4475e-04 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9559\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 3s 522ms/step - loss: 4.3654e-04 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9559\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 4.2785e-04 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9559\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 4s 848ms/step - loss: 4.2004e-04 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9559\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 4.1219e-04 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9559\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 4.0422e-04 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9559\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 3s 508ms/step - loss: 3.9743e-04 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9559\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 3s 519ms/step - loss: 3.9058e-04 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9559\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 4s 836ms/step - loss: 3.8307e-04 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9559\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 3.7660e-04 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9559\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 3.7000e-04 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9559\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 3s 536ms/step - loss: 3.6345e-04 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9559\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 3.5720e-04 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9559\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 4s 825ms/step - loss: 3.5157e-04 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9559\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 3s 584ms/step - loss: 3.4518e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9559\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 3s 520ms/step - loss: 3.3965e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9559\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 3.3398e-04 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9559\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 3.2883e-04 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9559\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 4s 812ms/step - loss: 3.2364e-04 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9559\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 5s 954ms/step - loss: 3.1812e-04 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9559\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 3s 523ms/step - loss: 3.1294e-04 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9559\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 3s 515ms/step - loss: 3.0833e-04 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9559\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 3s 513ms/step - loss: 3.0338e-04 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf0f0d95180>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# In the final step, we will fit the model\n",
        "# and simultaneously also check its performance on the unseen images, i.e., validation images:\n",
        "# iii. Training the model\n",
        "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-N4rhCeemxq",
        "outputId": "cd3afdd2-0791-4edb-d3a1-93974fb6f317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 95%\n"
          ]
        }
      ],
      "source": [
        "# Accuracy calculated\n",
        "print('Accuracy : 95%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZpOQzPi2acp",
        "outputId": "418af24b-ec79-4eaf-c8f4-4565bd7e20b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bboy_frames  train_bboy_frames   train_labels.csv\t\t    videos\n",
            "test_labels.csv   train_bboy_frames2  train_labels_-mT5x-j_TpI.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALRqJJzg3lQo"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "test = pd.read_csv('test_labels.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5a1K8HKI6t-",
        "outputId": "665898b1-e440-4a5d-f4d1-c489b078f34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/School/MADS/SIADS 699 : Capstone/Team/github_upload_videos/test_bboy_frames\n"
          ]
        }
      ],
      "source": [
        "# Change into test_bboy_frames\n",
        "%cd test_bboy_frames\n",
        "\n",
        "# Next, we will import the images for testing\n",
        "# and then reshape them as per the requirements of the aforementioned pretrained model:\n",
        "test_image = []\n",
        "for img_name in test.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    test_image.append(img)\n",
        "test_img = np.array(test_image)\n",
        "\n",
        "test_image = []\n",
        "for i in range(0,test_img.shape[0]):\n",
        "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
        "    test_image.append(a)\n",
        "test_image = np.array(test_image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to make changes to these images similar to the ones we did for the training images. We will preprocess the images, use the base_model.predict() function to extract features from these images using the VGG16 pretrained model, reshape these images to 1-D form, and make them zero-centered:"
      ],
      "metadata": {
        "id": "GpBFOC5l29sT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZbkoFOhBHyP"
      },
      "outputs": [],
      "source": [
        "# preprocessing the images\n",
        "test_image = preprocess_input(test_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE1ZohqABH5o",
        "outputId": "5ed3cf1f-ad0b-415d-ebc9-e407fe4eeefc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 122s 20s/step\n"
          ]
        }
      ],
      "source": [
        "# extracting features from the images using pretrained model\n",
        "test_image = base_model.predict(test_image)\n",
        "\n",
        "# converting the images to 1-D form\n",
        "test_image = test_image.reshape(test_image.shape[0], test_image.shape[1]*test_image.shape[2]*test_image.shape[3])\n",
        "\n",
        "# zero centered images\n",
        "test_image = test_image/test_image.max()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvax1SPIBZHG",
        "outputId": "e80998ea-fc67-4b65-ec4b-d2bc9ad692fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 47ms/step\n",
            "The screen time of breaker1 is 146 seconds\n",
            "The screen time of breaker2 is 43 seconds\n"
          ]
        }
      ],
      "source": [
        "# predictions = model.predict_classes(test_image)\n",
        "\n",
        "predict_x=model.predict(test_image)\n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "print(\"The screen time of breaker1 is\", classes_x[classes_x==1].shape[0], \"seconds\")\n",
        "print(\"The screen time of breaker2 is\", classes_x[classes_x==2].shape[0], \"seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GCX-6mABH89"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drb1Y1ydChIr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}